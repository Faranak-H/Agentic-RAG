# Whether to use the HuggingFace API or Ollama
# Set this to yes or no
USE_HUGGINGFACE=yes

# This token is optional but you'll have more restrictive rate limits and model options without it
# Get your HuggingFace token from https://huggingface.co/settings/tokens
HUGGINGFACE_API_TOKEN=" "

# The model ID to use from HuggingFace for drafting with LLM
# Example: meta-llama/Llama-3.3-70B-Instruct
DRAFT_MODEL_ID=meta-llama/Llama-3.3-70B-Instruct

# The model ID to use from HuggingFace for the reasoning LLM. 
# Get this by visiting the model page on HuggingFace and copying the ID in the URL or in the top left of the page
# Example: deepseek-ai/DeepSeek-R1-Distill-Qwen-32B
CONTROL_MODEL_ID=deepseek-ai/DeepSeek-R1-Distill-Qwen-32B
